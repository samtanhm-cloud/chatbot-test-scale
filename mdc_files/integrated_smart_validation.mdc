---
name: Integrated Smart Email Validation (All-in-One)
description: Single-prompt validation - curl + pattern + selective browser - fully automated
version: 6.7.2
author: AI Assistant
changelog: |
  v6.7.2 - HYBRID TIMEOUT HANDLING & LANGUAGE MATCHING (CRITICAL FIXES)
    ‚Ä¢ ADDED: Hybrid timeout handling - DNS errors (exit 6) marked as instant BROKEN
    ‚Ä¢ ADDED: Language matching for HTTP 200 - wrong language codes now flagged
    ‚Ä¢ ADDED: Language matching for HTTP 403 whitelist - only whitelists matching language
    ‚Ä¢ FIXED: Timeouts on Autodesk domains now flagged for browser test (not instant BROKEN)
    ‚Ä¢ FIXED: HTTP 200 with wrong language (e.g., /es/ in Japanese email) now detected
    ‚Ä¢ FIXED: HTTP 403 whitelist now validates language matches email language
    ‚Ä¢ Example: ja email + /es/support ‚Üí Flagged as WRONG_LANGUAGE ‚Üí Tests /ja/support
    ‚Ä¢ Example: Timeout on autodesk.com ‚Üí Browser test (bot protection, not broken)
    ‚Ä¢ Example: DNS error on autoesk.com ‚Üí Instant BROKEN (typo domain)
    ‚Ä¢ Impact: Catches language mismatches across ALL HTTP codes + smarter timeout handling
  v6.7.1 - 403 LOCALIZATION STATUS FIX (CRITICAL BUG FIX)
    ‚Ä¢ FIXED: Non-whitelisted 403 URLs now properly track localization status for Phase 3 testing
    ‚Ä¢ FIXED: Phase 2 was setting localizationStatus="N/A" for all non-whitelisted 403s (line 958)
    ‚Ä¢ CHANGED: Now checks if URL is localized before marking - sets "NOT_LOCALIZED" for non-English emails
    ‚Ä¢ IMPACT: Phase 3 now correctly tests localized variants (e.g., /cz/support) for 403 URLs
    ‚Ä¢ Example: Czech email with /support (403) ‚Üí now tests /cz/support ‚Üí finds localized version
    ‚Ä¢ This fixes a critical bug where localized pages existed but weren't discovered/recommended
  v6.7.0 - CORRECTED FLOW & CONDITIONAL ENGLISH WHITELIST (CRITICAL FIX)
    ‚Ä¢ FIXED: Localization check now happens BEFORE 403 whitelist decision (was skipping localization!)
    ‚Ä¢ FIXED: Broken links (404/500) now skip localization check entirely (no point checking if broken)
    ‚Ä¢ ADDED: Conditional English whitelist - only applies when EMAIL language = "en"
    ‚Ä¢ CHANGED: English pages in non-English emails now flagged for localization check
    ‚Ä¢ Correct flow: 1) Check broken 2) Check localized 3) Apply whitelist OR flag for browser test
    ‚Ä¢ Example: Polish email with /support link ‚Üí NOT whitelisted ‚Üí browser checks for /pl/support
    ‚Ä¢ Example: English email with /support link ‚Üí Whitelisted ‚Üí marked OK (403)
    ‚Ä¢ HTTP 200 + size >= 1KB + not localized + non-English email ‚Üí browser test for /xx/ variant
    ‚Ä¢ This is a CRITICAL fix - previous versions could miss non-localized links in non-English emails!
  v6.6.1 - 429 EXCLUSION & COLLECTIONS PATTERN
    ‚Ä¢ CHANGED: 429 errors now skip browser testing (assumed temporary rate limits)
    ‚Ä¢ ADDED: /xx/collections pattern to 403 whitelist (e.g., /br/collections, /jp/collections)
    ‚Ä¢ 429 ‚Üí ‚ö†Ô∏è RATE-LIMITED (no browser test, saves 5-10s per occurrence)
    ‚Ä¢ CSV will show: "Consider reviewing - rate limit detected but not verified"
    ‚Ä¢ Speed improvement: ~5-10s faster for emails with 429 errors
  v6.6.0 - SMART 403 HANDLING & BOT DETECTION (Pattern-Based)
    ‚Ä¢ ADDED: Pattern-based 403 whitelist (specific URL patterns, not entire domains)
    ‚Ä¢ ADDED: Smart bot-block detection (403, 429, 503 with small content)
    ‚Ä¢ Whitelisted patterns:
      - /xx/ (language homepages: /br/, /jp/, /de/)
      - /xx/support (language support pages)
      - /xx/products (language product pages)
      - /xx/collections (language collections pages)
      - /xx/support/account|technical|download-install (support subdirectories)
      - knowledge.autodesk.com/* (knowledge base)
      - forums.autodesk.com/* (community forums)
    ‚Ä¢ 403 matching pattern ‚Üí ‚úÖ OK (known bot detection, skip browser test)
    ‚Ä¢ 403 NOT matching ‚Üí ‚ö†Ô∏è BOT-BLOCKED (browser test required - may be genuinely restricted)
    ‚Ä¢ 429 (Rate Limiting) ‚Üí ‚ö†Ô∏è RATE-LIMITED (browser test required)
    ‚Ä¢ 503 with <5KB content ‚Üí ‚ö†Ô∏è SUSPICIOUS (likely Cloudflare block, browser test required)
    ‚Ä¢ More accurate than domain-only whitelisting (avoids false negatives)
  v6.5.2 - CSV FORMAT SPECIFICATION & ENHANCEMENT
    ‚Ä¢ CLARIFIED: Phase 4 CSV format is now explicitly documented with column descriptions
    ‚Ä¢ REQUIRED FORMAT: "CTA #,Anchor Text,Link URL,HTTP Status,Localization Status,Browser Verification,Recommendation"
    ‚Ä¢ FIXED: HTTP Status now combines emoji + code (e.g., "‚úÖ OK (200)", "‚ùå BROKEN (404)")
    ‚Ä¢ ENHANCED: Recommendation logic now handles anchor placeholders and not-localized links specifically
    ‚Ä¢ Anchor Text column populated from extraction data (.allLinks[].text)
    ‚Ä¢ Better actionable recommendations (e.g., "Fix: Use localized version: https://...")
  v6.5.1 - TERMINAL BUFFER FIX (CRITICAL)
    ‚Ä¢ FIXED: Phase 3.5 (Verification Checkpoint) terminal stall-out by using temp script approach
    ‚Ä¢ FIXED: Phase 5 (CSV preview + cleanup) terminal stall-out by using temp script approach
    ‚Ä¢ Both phases now create /tmp/verify_*.sh and /tmp/phase5_*.sh scripts
    ‚Ä¢ Prevents terminal buffer overflow from long commands with Unicode characters
    ‚Ä¢ Ensures reliable execution on all terminal configurations
  v6.5.0 - EXECUTION SAFEGUARDS & SOCIAL MEDIA EXCLUSION
    ‚Ä¢ ADDED: Explicit "DO NOT SKIP" warnings in Phase 3 to prevent AI deviation
    ‚Ä¢ ADDED: Automatic social media link exclusion (facebook, twitter, linkedin, instagram, youtube)
    ‚Ä¢ ADDED: Verification checkpoint after Phase 3 (ensures no steps were skipped)
    ‚Ä¢ ADDED: Self-check before Phase 4 (validates browserVerified counts)
    ‚Ä¢ Social links flagged as "‚úÖ SOCIAL MEDIA (No local version)" and skip browser testing
  v6.4.0 - AI-BASED LANGUAGE DETECTION
    ‚Ä¢ ADDED: AI content analysis for accurate language detection (replaces unreliable metadata)
    ‚Ä¢ Priority: URL pattern ‚Üí AI content analysis ‚Üí Script detection ‚Üí Metadata (fallback only)
    ‚Ä¢ Handles mixed-language pages (platform UI in English, email content in other languages)
    ‚Ä¢ Works for all Latin-based languages (Polish, German, French, Spanish, Italian, etc.)
    ‚Ä¢ Cost: +$0.003 per email (~2% increase) for 100% accurate language detection
  v6.3.0 - STABILITY & VALIDATION FIXES
    ‚Ä¢ FIXED: Prevents terminal stall-out by using temporary script files instead of long inline commands
    ‚Ä¢ FIXED: Non-localized URLs now correctly flagged with needsBrowserTest: true for Phase 3 verification
    ‚Ä¢ Phase 2 creates /tmp/validate_*.sh script to avoid command-line length limits
    ‚Ä¢ Non-localized URLs (e.g., /learn/) now properly tested for local version existence in Phase 3
  v6.2.0 - CRITICAL FIXES
    ‚Ä¢ FIXED: Phase 3 now actually executes Playwright browser testing (was only documenting, not executing)
    ‚Ä¢ FIXED: Removed hardcoded example URL (was 3935434, now generic XXXXXX)
    ‚Ä¢ Phase 3 now properly launches browser for soft 404 detection and localization verification
    ‚Ä¢ All flagged URLs (needsBrowserTest: true) are now actually tested with Playwright
  v6.1.0 - PATTERN RECOGNITION ENHANCED
    ‚Ä¢ Added anchor placeholder (#) detection - flags as potential missing links
    ‚Ä¢ Added legal/privacy footer exclusion - auto-passes standard footer links
    ‚Ä¢ Patterns: /company/legal-notices-trademarks*, privacy-statement-*
  v6.0.0 - INTEGRATED - All phases automated in single MDC execution
    ‚Ä¢ User provides email URL ‚Üí AI handles everything automatically
    ‚Ä¢ Phase 1: Playwright extraction (automated)
    ‚Ä¢ Phase 2: curl + pattern validation (automated via terminal commands)
    ‚Ä¢ Phase 3: Selective browser testing (automated)
    ‚Ä¢ Phase 4: CSV generation (automated)
---

# Integrated Smart Email Validation (v6.7.2)

## üéØ What This Does

**Single-prompt, fully automated validation:**
- User provides email preview URL
- AI executes all 4 phases automatically
- Generates CSV report
- Cleans up temp files
- **No manual steps required**

## üí° Key Innovation: Seamless Integration

The AI assistant executing this MDC will:
1. Use `browser_navigate` for Playwright operations
2. Use `run_terminal_cmd` for bash/curl operations
3. Coordinate between tools automatically
4. Generate final CSV without user intervention

---

## üìã Execution Instructions for AI Assistant

### USER INPUT REQUIRED:
- Email preview URL (e.g., `https://webpub.autodesk.com/draftr/preview/XXXXXX`)

### ‚ö†Ô∏è CRITICAL: AI MUST FOLLOW THESE RULES

**This MDC has automated validation checkpoints to catch execution errors:**

1. **Phase 2 - 403 Handling (Lines 499-525)**
   - ALL 403 responses MUST be checked against pattern whitelist
   - Non-whitelisted 403s MUST be flagged with `needsBrowserTest: true`
   - DO NOT assume 403 = "bot-blocked but working" without verification

2. **Phase 2.5 - Mandatory Checkpoint (Lines 951-1005)**
   - This checkpoint will FAIL if Phase 2 was executed incorrectly
   - If checkpoint fails: STOP, re-implement Phase 2, re-run checkpoint
   - If checkpoint passes: Proceed to Phase 3 (if needed) or Phase 4

3. **Phase 3 - Browser Testing (Lines 1008+)**
   - MUST execute if ANY links have `needsBrowserTest: true`
   - Use `mcp_playwright-extension_browser_navigate()` for validation
   - DO NOT skip based on assumptions

**These checkpoints prevent the error where AI assumes 403s are working without browser verification.**

### AI EXECUTES AUTOMATICALLY:

---

### ‚úÖ TODO LIST (AI MUST CREATE FIRST)

```
TODO items (v6.7.2 - Hybrid Timeout + Language Matching):
1. ‚òê PHASE 1: Extract links + detect language (Playwright)
2. ‚òê PHASE 1.2: AI content analysis for accurate language detection
3. ‚òê PHASE 1.5: Save extraction data to temp file (terminal)
4. ‚òê PHASE 2: Smart validation with HYBRID TIMEOUT + LANGUAGE MATCHING
5. ‚òê PHASE 3: Selective browser testing (Playwright - only flagged URLs)
6. ‚òê PHASE 3.5: VERIFICATION CHECKPOINT (prevent AI deviation)
7. ‚òê PHASE 4: Generate CSV report with REQUIRED FORMAT (terminal)
8. ‚òê PHASE 5: Verify CSV + cleanup (combined)
```

---

## PHASE 1: Extract Links with Playwright

**Step 1.1: Navigate to Email Preview**

**Tools:** `browser_navigate(EMAIL_URL)` ‚Üí `browser_wait_for({ time: 3 })`

**Step 1.2: Extract + Detect + Deduplicate**

**Tool:** `browser_evaluate(extractLinksDetectLanguageAndDeduplicate)`

**‚ö†Ô∏è CRITICAL:** This function includes ALL checks from v4.1.1:
- ‚úÖ Universal language detection (15+ languages)
- ‚úÖ Visibility-based extraction (excludes hidden elements)
- ‚úÖ Platform navigation exclusion (Draftr/Litmus toolbar)
- ‚úÖ Template variable filtering ({{, system.)
- ‚úÖ Deduplication

```javascript
function extractLinksDetectLanguageAndDeduplicate() {
    const DEBUG = false;
    
    function log(msg, level = 'info') {
        if (DEBUG || level === 'error') console.log(msg);
    }
    
    log('üöÄ Starting email validation...');
    
    // ============================================
    // PART A: PRELIMINARY LANGUAGE DETECTION
    // ============================================
    // ‚ö†Ô∏è NOTE: This is PRELIMINARY detection only!
    // Phase 1.2 (AI analysis) will override this with accurate result.
    // This preliminary check is kept for:
    //   1. URL patterns (if found, likely correct)
    //   2. Fallback if AI detection fails
    
    log('üåç Detecting page language (preliminary)...');
    
    const bodyText = document.body ? document.body.textContent : '';
    const titleText = document.title;
    const htmlLang = document.documentElement.lang;
    const metaLang = document.querySelector('meta[name="content-language"]')?.getAttribute('content');
    const ogLocale = document.querySelector('meta[property="og:locale"]')?.getAttribute('content');
    
    // METHOD 1: URL Pattern Detection (Most Reliable)
    const detectLanguageFromUrl = (pathname, search) => {
        const fullPath = pathname + search;
        const patterns = {
            '/ja/': 'ja', '/jp/': 'ja',
            '/de/': 'de', '/fr/': 'fr',
            '/es/': 'es', '/pt/': 'pt', '/br/': 'pt',
            '/ko/': 'ko', '/kr/': 'ko',
            '/zh/': 'zh', '/cn/': 'zh', '/tw/': 'zh',
            '/ar/': 'ar', '/ru/': 'ru',
            '/th/': 'th', '/hi/': 'hi',
            '/el/': 'el', '/he/': 'he',
            '/it/': 'it', '/pl/': 'pl'
        };
        
        for (const [pattern, lang] of Object.entries(patterns)) {
            if (fullPath.includes(pattern)) return lang;
        }
        
        const langMatch = fullPath.match(/[?&]lang=([a-z]{2})/);
        if (langMatch) return langMatch[1];
        
        const localeMatch = fullPath.match(/[?&]locale=([a-z]{2})/);
        if (localeMatch) return localeMatch[1];
        
        return null;
    };
    
    // METHOD 2: Script Detection (Unicode Ranges)
    const detectLanguageByScript = (text) => {
        if (/[\u4E00-\u9FFF]/.test(text)) return 'zh';
        if (/[\u3040-\u309F\u30A0-\u30FF]/.test(text)) return 'ja';
        if (/[\uAC00-\uD7AF]/.test(text)) return 'ko';
        if (/[\u0600-\u06FF]/.test(text)) return 'ar';
        if (/[–∞-—è—ë]/.test(text)) return 'ru';
        if (/[\u0E00-\u0E7F]/.test(text)) return 'th';
        if (/[\u0900-\u097F]/.test(text)) return 'hi';
        if (/[\u0370-\u03FF]/.test(text)) return 'el';
        if (/[\u0590-\u05FF]/.test(text)) return 'he';
        return null;
    };
    
    // HYBRID DETECTION
    const results = {};
    const urlResult = detectLanguageFromUrl(window.location.pathname, window.location.search);
    if (urlResult) results.url = urlResult;
    
    const metadataResult = htmlLang || metaLang || ogLocale;
    if (metadataResult) results.metadata = metadataResult;
    
    const scriptResult = detectLanguageByScript(bodyText);
    if (scriptResult) results.script = scriptResult;
    
    let detectedLanguage = 'en';
    if (results.url) detectedLanguage = results.url;
    else if (results.metadata) detectedLanguage = results.metadata;
    else if (results.script) detectedLanguage = results.script;
    
    console.log(`üåç Language detected (preliminary): ${detectedLanguage}`);
    
    // ============================================
    // PART B: EXTRACT EMAIL LINKS (VISIBILITY-BASED)
    // ============================================
    
    log('üîç Extracting email template links...');
    
    const allLinks = Array.from(document.querySelectorAll('a[href]'));
    log(`   Found ${allLinks.length} total anchor tags`);
    
    // Identify platform navigation (Draftr, Litmus, etc.)
    const platformNavIdentifiers = [
        document.querySelector('img[alt="Autodesk Draftr"]'),
        document.querySelector('img[alt="Litmus"]'),
        document.querySelector('[class*="preview-toolbar"]'),
        document.querySelector('[id*="email-preview-nav"]')
    ];
    const platformNav = platformNavIdentifiers.find(el => el)?.closest('div');
    
    const emailLinks = [];
    
    allLinks.forEach((link) => {
        const href = link.getAttribute('href');
        if (!href || href.includes('javascript:')) return;
        if (href.includes('{{') || href.includes('system.')) return;
        
        const anchorText = (link.innerText || '').trim();
        const hasImage = !!link.querySelector('img');
        
        const rect = link.getBoundingClientRect();
        const isVisible = (
            rect.width > 0 && 
            rect.height > 0 && 
            window.getComputedStyle(link).visibility !== 'hidden' &&
            window.getComputedStyle(link).display !== 'none'
        );
        
        const isInPlatformNav = platformNav ? platformNav.contains(link) : false;
        const isValid = isVisible && !isInPlatformNav;
        
        if (isValid) {
            emailLinks.push({
                href: href,
                text: anchorText || 'Image Link',
                isImageLink: hasImage && !anchorText
            });
        }
    });
    
    console.log(`‚úÖ Extracted ${emailLinks.length} valid email links`);
    log(`   ‚ùå Filtered out ${allLinks.length - emailLinks.length} non-email links`);
    
    // ============================================
    // PART C: DEDUPLICATE FOR EFFICIENT TESTING
    // ============================================
    
    log(`üîÑ Deduplicating ${emailLinks.length} CTAs...`);
    
    const uniqueUrlMap = new Map();
    
    emailLinks.forEach((link, index) => {
        const url = link.href;
        
        if (!uniqueUrlMap.has(url)) {
            uniqueUrlMap.set(url, {
                testUrl: url,
                firstAnchorText: link.text,
                isImageLink: link.isImageLink,
                ctaIndices: [index]
            });
        } else {
            uniqueUrlMap.get(url).ctaIndices.push(index);
        }
    });
    
    const uniqueUrls = Array.from(uniqueUrlMap.values());
    const testableUrls = uniqueUrls.filter(u => 
        !u.testUrl.includes('{{') && 
        !u.testUrl.includes('system.') &&
        (u.testUrl.startsWith('http://') || u.testUrl.startsWith('https://'))
    );
    
    console.log(`‚úÖ ${uniqueUrls.length} unique URLs (${testableUrls.length} testable)`);
    
    // ============================================
    // PART D: RETURN COMPLETE DATA STRUCTURE
    // ============================================
    
    // Create content sample for AI language detection
    // Extract visible anchor texts (actual email content, not platform UI)
    const contentSample = emailLinks
        .map(link => link.text)
        .filter(text => text && text !== 'Image Link')
        .join(' ')
        .substring(0, 1000); // First 1000 chars for AI analysis
    
    const extractionData = {
        detectedLanguage: detectedLanguage,
        languageMethods: results,
        confidence: Object.keys(results).length > 1 ? 'high' : 'low',
        pageUrl: window.location.href,
        pageTitle: document.title,
        contentLength: bodyText.length,
        contentSample: contentSample, // For AI language detection
        allLinks: emailLinks,
        totalLinks: emailLinks.length,
        uniqueUrls: testableUrls,
        uniqueUrlCount: testableUrls.length,
        urlMap: Object.fromEntries(uniqueUrlMap),
        timestamp: new Date().toISOString()
    };
    
    console.log('‚úÖ Extraction complete - data ready for persistence');
    
    return extractionData;
}
```

---

## PHASE 1.2: AI Language Detection

**Purpose:** Analyze actual email content to determine true language (ignores platform metadata)

**Tool:** `codebase_search` (uses AI for content analysis)

**‚ö†Ô∏è CRITICAL:** This replaces unreliable metadata detection from Part A. Works for mixed-language pages (English platform UI + Polish/French/etc. email content).

**Step 1.2.1: Prepare content sample**

From Phase 1 extraction result, extract the `contentSample` field:

```javascript
// Example from Phase 1 result:
{
  "contentSample": "konto w portalu Autodesk Account Przejrzyj zakupione subskrypcje...",
  // ... other fields
}
```

**Step 1.2.2: Call AI for language detection**

Use the `codebase_search` tool with a specific query:

**Query:** "What is the primary language of this email content? Respond with ONLY the 2-letter ISO language code (e.g., 'en', 'pl', 'fr', 'ko', 'ja', 'de', 'es', 'it', 'pt', 'zh', 'ar', 'ru', 'th', 'hi'). Content sample: [PASTE_CONTENT_SAMPLE_HERE]"

**Parameters:**
- `target_directories`: [] (not searching code, using AI inference)
- `explanation`: "Detecting email content language for accurate localization validation"

**Expected Response:** A 2-letter language code like "pl", "fr", "ko", etc.

**Step 1.2.3: Update detectedLanguage with AI result (with fallback)**

Smart override logic - only replace Part A result when appropriate:

```javascript
// Get preliminary detection from Part A
const preliminaryLanguage = extractionData.detectedLanguage; // e.g., "en"
const hasUrlPattern = extractionData.languageMethods.url !== undefined;

// Try AI detection
let finalLanguage = preliminaryLanguage; // Default: keep Part A result

if (hasUrlPattern) {
    // URL pattern found (e.g., /pl/ or ?lang=ko)
    // Keep it - URL patterns are explicit and reliable
    console.log(`‚úÖ Keeping URL-based detection: ${preliminaryLanguage}`);
    finalLanguage = preliminaryLanguage;
    
} else if (aiDetectedLanguage && aiDetectedLanguage !== 'error') {
    // AI detection succeeded and URL pattern not found
    // Override Part A with AI result
    console.log(`ü§ñ AI detected: ${aiDetectedLanguage} (overriding preliminary: ${preliminaryLanguage})`);
    finalLanguage = aiDetectedLanguage;
    extractionData.languageMethods.ai = aiDetectedLanguage;
    extractionData.confidence = 'high';
    
} else {
    // AI failed - fall back to Part A result
    console.log(`‚ö†Ô∏è AI detection failed, using fallback: ${preliminaryLanguage}`);
    extractionData.languageMethods.aiFailed = true;
}

// Update final language
extractionData.detectedLanguage = finalLanguage;
```

**Priority Logic (Final):**
```
1. URL pattern (/pl/, ?lang=ko) 
   ‚Üí If found in Part A, KEEP IT (explicit, highest confidence)
   ‚Üí Skip AI detection (unnecessary)

2. AI content analysis (Phase 1.2)
   ‚Üí If no URL pattern, call AI
   ‚Üí Override Part A result with AI result
   ‚Üí High confidence (95%+)

3. Part A fallback
   ‚Üí If AI fails, use Part A result (metadata/script)
   ‚Üí Better than nothing
   ‚Üí Low confidence (often wrong)
```

**Step 1.2.4: Mark TODO #1 & #1.2 Complete**

---

## PHASE 1.5: Save Extraction Data

**Tool:** `run_terminal_cmd`

**‚ö†Ô∏è CRITICAL:** Use temp script approach to avoid command-line length limits with Unicode content.

```bash
# Extract preview ID from URL
PREVIEW_ID=$(echo "EMAIL_URL" | grep -oP 'preview/\K\d+')
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
TEMP_FILE="/tmp/email_extraction_${PREVIEW_ID}_${TIMESTAMP}.json"

# Create temp script to save JSON (avoids command-line length limits)
SAVE_SCRIPT="/tmp/save_extraction_$(date +%s).sh"

cat > "$SAVE_SCRIPT" << 'SCRIPT_EOF'
#!/bin/bash
TEMP_FILE="$1"

# Save COMPLETE JSON output from Phase 1
cat > "$TEMP_FILE" << 'JSON_EOF'
<PASTE_FULL_JSON_FROM_PHASE_1>
JSON_EOF

echo "‚úÖ Saved to: $TEMP_FILE"
ls -lh "$TEMP_FILE"

# Validate allLinks array presence
if jq -e '.allLinks' "$TEMP_FILE" > /dev/null 2>&1; then
    LINK_COUNT=$(jq '.allLinks | length' "$TEMP_FILE")
    echo "‚úÖ Validation passed: allLinks array contains $LINK_COUNT items"
else
    echo "‚ùå FATAL ERROR: allLinks array missing from saved file!"
    echo "   Phase 4 CSV generation will fail without anchor text data."
    exit 1
fi
SCRIPT_EOF

chmod +x "$SAVE_SCRIPT" && "$SAVE_SCRIPT" "$TEMP_FILE"
```

**Step 1.4: Mark TODO #2 Complete**

---

## PHASE 2: Smart Validation (curl + Pattern Matching)

**Tool:** `run_terminal_cmd`

**IMPORTANT:** Create a temporary shell script to avoid command-line length limits and stalling.

This phase runs entirely in terminal - no Playwright needed.

---

### ‚ö†Ô∏è CRITICAL AI EXECUTION INSTRUCTIONS FOR PHASE 2

**DO NOT SKIP OR MODIFY THIS LOGIC:**

1. **403 Handling - Pattern-Based Whitelist (Lines 682-790)**
   - ‚úÖ ALL 403s MUST be checked against pattern whitelist
   - ‚úÖ Whitelisted patterns: `/$PAGE_LANG/`, `/support`, `/products`, `/collections`, `forums.autodesk.com`, `knowledge.autodesk.com`
   - ‚úÖ IF 403 matches whitelist ‚Üí `needsBrowserTest: false` (known bot detection)
   - ‚úÖ IF 403 DOES NOT match whitelist ‚Üí `needsBrowserTest: true` (REQUIRES Phase 3 browser test)
   - ‚ùå DO NOT assume all 403s are "bot-blocked but working"
   - ‚ùå DO NOT skip browser testing for non-whitelisted 403s

2. **Verification Checkpoint After Phase 2**
   - Count links with `needsBrowserTest: true`
   - If email has 4+ links returning 403, expect 2-4 to be flagged for browser testing
   - If 0 flagged but 403s exist ‚Üí YOU MADE AN ERROR, re-implement Phase 2 correctly

3. **Phase 3 is NOT Optional**
   - Phase 3 MUST run if ANY links have `needsBrowserTest: true`
   - Use `mcp_playwright-extension_browser_navigate()` for actual validation
   - DO NOT skip Phase 3 based on assumptions

**Test Case**: For Spanish email with `https://www.autodesk.com/learn/` returning 403:
- ‚ùå WRONG: Assume working, skip browser test
- ‚úÖ CORRECT: `/learn/` not in whitelist ‚Üí flag `needsBrowserTest: true` ‚Üí Phase 3 verifies with browser

---

## üìã PHASE 2 DECISION LOGIC (AI Must Implement Exactly)

This section documents ALL decision rules for Phase 2. The shell script below **implements** these rules.

**AI Assistant**: Do not deviate from these rules. They are requirements, not suggestions.

---

### 1Ô∏è‚É£ LINK TYPE CLASSIFICATION (Pre-Validation Exclusions)

**Purpose**: Some links don't need HTTP validation or localization checks.

| Link Pattern | Classification | Action | Reason |
|-------------|----------------|--------|---------|
| `#` | MISSING_LINK | Skip validation | Anchor placeholder, no target URL |
| `/company/legal-notices-trademarks*` | LEGAL_FOOTER | Mark as OK, skip | Preloaded in browser, always accessible |
| `/privacy-statement*` | PRIVACY_FOOTER | Mark as OK, skip | Preloaded in browser, always accessible |
| `facebook.com\|twitter.com\|linkedin.com\|instagram.com\|youtube.com` | SOCIAL_MEDIA | Mark as OK, skip | No localized versions exist |
| `accounts.autodesk.com` | GLOBAL_SERVICE | Mark as OK, skip | Global auth service, always English |
| `manage.autodesk.com` | GLOBAL_SERVICE | Mark as OK, skip | Global management portal, always English |
| `forums.autodesk.com` | GLOBAL_SERVICE | Mark as OK, skip | Global forums, no localization |

**Implementation**: Check these patterns FIRST before any HTTP validation.

---

### 2Ô∏è‚É£ HTTP STATUS INTERPRETATION

**Purpose**: Determine link health based on HTTP status code.

| HTTP Code | Status | Next Action | needsBrowserTest |
|-----------|--------|-------------|------------------|
| 200-299 | OK | Check localization (see rule 5) | Depends on rule 5 |
| 403 | BOT_BLOCKED or BROKEN | Check whitelist (see rule 3) | Depends on rule 3 |
| 404, 410 | BROKEN | Mark as broken, report | `false` |
| 429 | RATE_LIMITED | Mark as OK (temporary) | `false` |
| 500-599 | SERVER_ERROR | Mark as server error, report | `false` |
| Timeout | CONNECTION_ERROR | Mark as connection error | `false` |
| DNS failure | BROKEN | Mark as broken (domain issue) | `false` |

**Implementation**: Use `curl` with `-L` (follow redirects), capture status code and final URL.

---

### 3Ô∏è‚É£ 403 WHITELIST PATTERNS (Known Bot Protection)

**Purpose**: Distinguish between "403 due to bot protection" vs "403 actually broken".

**Whitelist Logic**:
- IF URL matches ANY pattern below ‚Üí `needsBrowserTest = false` (known bot protection)
- IF URL DOES NOT match ‚Üí `needsBrowserTest = true` (requires Phase 3 browser test)

#### **Localized Patterns** (All Languages):
Match if URL contains `/$LANG/` where `$LANG` = 2-3 letter language code:

| Pattern | Example | Reason |
|---------|---------|--------|
| `www.autodesk.com/$LANG/?` | `www.autodesk.com/ja/` | Localized homepage |
| `www.autodesk.com/$LANG/support*` | `www.autodesk.com/es/support/contact` | Localized support |
| `www.autodesk.com/$LANG/products*` | `www.autodesk.com/de/products/autocad` | Localized products |
| `www.autodesk.com/$LANG/collections*` | `www.autodesk.com/fr/collections/aec` | Localized collections |
| `www.autodesk.com/$LANG/buying*` | `www.autodesk.com/pt/buying/plans` | Localized buying |

#### **English-Only Patterns** (Only if Email Language = English):
Match ONLY if `$EMAIL_LANG = "en"`:

| Pattern | Example | Reason |
|---------|---------|--------|
| `www.autodesk.com/?` | `www.autodesk.com/` | English homepage |
| `www.autodesk.com/support*` | `www.autodesk.com/support/contact` | English support |
| `www.autodesk.com/buying*` | `www.autodesk.com/buying/plans` | English buying |
| `www.autodesk.com/mkto-unsubscribe*` | `www.autodesk.com/mkto-unsubscribe?id=123` | Unsubscribe |

#### **Domain Patterns** (Always Whitelisted):
Match by domain regardless of path:

| Domain | Example | Reason |
|--------|---------|--------|
| `knowledge.autodesk.com` | `knowledge.autodesk.com/support/autocad` | Knowledge base (bot protected) |
| `forums.autodesk.com` | `forums.autodesk.com/t5/autocad-forum/bd-p/81` | Forums (bot protected) |
| `aps.autodesk.com` | `aps.autodesk.com/developer` | Developer platform |

**Critical**: This logic prevents the error where AI assumes all 403s are working.

---

### 4Ô∏è‚É£ LOCALIZATION DETECTION

**Purpose**: Determine if a URL is already localized (has language code in path/query).

**Detection Patterns**:

| Pattern | Regex | Example | Extracted Code |
|---------|-------|---------|----------------|
| 2-letter path | `\.(com\|net\|org)/[a-z]{2}(/\|$\|\\?)` | `autodesk.com/ja/support` | `ja` |
| 3-letter path | `\.(com\|net\|org)/[a-z]{3}(/\|$\|\\?)` | `autodesk.com/jpn/support` | `jpn` |
| Query param | `[?&](lang\|locale)=[a-z]{2}` | `?lang=es` or `?locale=fr` | `es`, `fr` |

**If Detected**:
- Set `IS_LOCALIZED = true`
- Extract `LANG_CODE`
- Mark as `ALREADY_LOCALIZED`
- Skip localization check (no need for browser test for localization)

**If Not Detected**:
- Set `IS_LOCALIZED = false`
- Proceed to rule 5 (localization requirement check)

---

### 5Ô∏è‚É£ BROWSER TEST DECISION MATRIX

**Purpose**: Determine which links need Phase 3 browser testing.

**Set `needsBrowserTest = true` IF ANY of:**

1. **HTTP 403 + NOT in whitelist** (rule 3)
   - Example: `https://www.autodesk.com/learn/` returns 403
   - `/learn/` not in whitelist ‚Üí Flag for browser test

2. **HTTP 200 + www.autodesk.com + NOT localized + Email NOT English**
   - Example: Email is Spanish, link is `https://www.autodesk.com/products/autocad`
   - No `/es/` in path ‚Üí Flag to check if localized version exists

**Set `needsBrowserTest = false` IF ANY of:**

1. **Link type exclusion** (rule 1)
   - Anchor, legal, social, global service

2. **HTTP 403 + in whitelist** (rule 3)
   - Known bot protection, assume working

3. **Already localized** (rule 4)
   - URL already has language code

4. **HTTP error** (not 200 or 403)
   - Already marked as broken/error

5. **Non-localizable domain**
   - `manage.autodesk.com`, `forums.autodesk.com`, etc.

---

### 6Ô∏è‚É£ OUTPUT FORMAT (JSON Structure)

**For each URL, generate:**

```json
{
  "originalUrl": "https://example.com/path",
  "status": "OK|BROKEN|BOT_BLOCKED|MISSING_LINK|RATE_LIMITED|SERVER_ERROR",
  "httpCode": "200|403|404|429|500|N/A",
  "localizationStatus": "ALREADY_LOCALIZED|NOT_LOCALIZED|NEEDS_CHECK|N/A",
  "needsBrowserTest": true|false,
  "reason": "Human-readable explanation of status and decision"
}
```

---

## üîß PHASE 2 IMPLEMENTATION

**Step 2.1: Create validation script file**

The script below **implements the decision logic documented above**. Do not modify the logic.

```bash
TEMP_FILE="/tmp/email_extraction_${PREVIEW_ID}_${TIMESTAMP}.json"
RESULTS_FILE="/tmp/smart_validation_${PREVIEW_ID}_${TIMESTAMP}.json"
DETECTED_LANGUAGE=$(jq -r '.detectedLanguage' "$TEMP_FILE")
VALIDATION_SCRIPT="/tmp/validate_${PREVIEW_ID}_${TIMESTAMP}.sh"

cat > "$VALIDATION_SCRIPT" << 'SCRIPTEOF'
#!/bin/bash
# ============================================================================
# Phase 2 Smart Validation Implementation
# ============================================================================
# This script implements the decision logic documented in sections 1-6 above.
# Do not modify the logic - it implements the explicit rules.
#
# References:
#   Rule 1: Link Type Classification (lines 556-570)
#   Rule 2: HTTP Status Interpretation (lines 574-588)
#   Rule 3: 403 Whitelist Patterns (lines 592-630)
#   Rule 4: Localization Detection (lines 634-655)
#   Rule 5: Browser Test Decision Matrix (lines 658-688)
#   Rule 6: Output Format (lines 691-704)
# ============================================================================

TEMP_FILE="$1"
RESULTS_FILE="$2"
EMAIL_LANG="$3"

echo "üìß Email language: $EMAIL_LANG"

echo '{"results": []}' > "$RESULTS_FILE"

# Helper function to write JSON results (reduces code duplication)
write_result() {
    local url="$1"
    local status="$2"
    local code="$3"
    local loc="$4"
    local browser="$5"
    local reason="$6"
    
    jq --arg url "$url" --arg status "$status" --arg code "$code" \
       --arg loc "$loc" --argjson browser "$browser" --arg reason "$reason" \
       '.results += [{"originalUrl": $url, "status": $status, "httpCode": $code,
                      "localizationStatus": $loc, "needsBrowserTest": $browser,
                      "reason": $reason}]' \
       "$RESULTS_FILE" > "${RESULTS_FILE}.tmp" && mv "${RESULTS_FILE}.tmp" "$RESULTS_FILE"
}

GLOBAL_SERVICES=("accounts.autodesk.com" "manage.autodesk.com" "forums.autodesk.com")

jq -r '.uniqueUrls[].testUrl' "$TEMP_FILE" | while read -r URL; do
    echo ""
    echo "üîç Testing: $URL"
    
    # Rule 1.1: Anchor placeholder check
    if [ "$URL" = "#" ]; then
        echo "   ‚ö†Ô∏è MISSING LINK: Anchor placeholder detected"
        write_result "$URL" "MISSING_LINK" "N/A" "N/A" false \
            "Anchor placeholder (#) detected - missing actual link target"
        continue
    fi
    
    # Rule 1.2: Legal/Privacy footer links
    if echo "$URL" | grep -qE '/company/legal-notices-trademarks(/privacy-statement)?$'; then
        echo "   ‚úÖ Legal/Privacy link (preloaded, skipped)"
        write_result "$URL" "OK" "N/A" "PRELOADED" false \
            "Legal/Privacy footer link - preloaded, no validation needed"
        continue
    fi
    
    # Rule 1.3: Social media links
    if echo "$URL" | grep -qE '(facebook\.com|twitter\.com|linkedin\.com|instagram\.com|youtube\.com)'; then
        SOCIAL_PLATFORM=$(echo "$URL" | grep -oE '(facebook|twitter|linkedin|instagram|youtube)' | head -1)
        echo "   ‚úÖ Social media: $SOCIAL_PLATFORM"
        write_result "$URL" "OK" "N/A" "SOCIAL_MEDIA" false \
            "Social media platform - no localized versions exist"
        continue
    fi
    
    # Rule 1.4: Global services
    DOMAIN=$(echo "$URL" | sed -E 's|https?://([^/]+).*|\1|')
    
    IS_GLOBAL=false
    for service in "${GLOBAL_SERVICES[@]}"; do
        if [[ "$DOMAIN" == "$service" ]]; then
            IS_GLOBAL=true
            break
        fi
    done
    
    if [ "$IS_GLOBAL" = true ]; then
        echo "   ‚úÖ Global service: $DOMAIN"
        write_result "$URL" "OK" "N/A" "GLOBAL_SERVICE" false \
            "Global service domain - always English, no localization"
        continue
    fi
    
    # Rule 2: HTTP validation via curl
    HTTP_OUTPUT=$(curl -o /dev/null -s -w "%{http_code}|%{size_download}|%{url_effective}" \
        -L --max-time 10 --max-redirs 5 --connect-timeout 5 "$URL" 2>&1) || CURL_EXIT=$?
    
    HTTP_CODE=$(echo "$HTTP_OUTPUT" | cut -d'|' -f1)
    CONTENT_SIZE=$(echo "$HTTP_OUTPUT" | cut -d'|' -f2)
    EFFECTIVE_URL=$(echo "$HTTP_OUTPUT" | cut -d'|' -f3)
    
    # Rule 2: Connection failures - HYBRID APPROACH
    if [ ${CURL_EXIT:-0} -ne 0 ]; then
        DOMAIN=$(echo "$URL" | sed -E 's|https?://([^/]+).*|\1|')
        
        # Exit code 6 = DNS resolution failed (domain doesn't exist)
        if [ "$CURL_EXIT" = "6" ]; then
            echo "   ‚ùå BROKEN: DNS resolution failed (domain doesn't exist: $DOMAIN)"
            write_result "$URL" "BROKEN" "DNS_ERROR" "N/A" false \
                "DNS resolution failed - domain '$DOMAIN' does not exist (likely typo)"
            continue
        fi
        
        # All other exit codes = ambiguous, needs browser verification
        echo "   ‚ö†Ô∏è Connection error (curl exit $CURL_EXIT) on $DOMAIN - flagging for browser test"
        write_result "$URL" "SUSPICIOUS" "TIMEOUT" "N/A" true \
            "Connection error on '$DOMAIN' (curl exit code $CURL_EXIT) - needs browser verification to determine if broken or bot-protected"
        continue
    fi
    
    if [ "$HTTP_CODE" = "404" ] || [ "$HTTP_CODE" = "410" ] || [ "$HTTP_CODE" = "500" ] || [ "$HTTP_CODE" = "502" ]; then
        echo "   ‚ùå BROKEN: HTTP $HTTP_CODE"
        write_result "$URL" "BROKEN" "$HTTP_CODE" "N/A" false \
            "HTTP $HTTP_CODE error"
        continue
    fi
    
    # Rule 4: Localization detection (checked before whitelist)
    IS_LOCALIZED=false
    LANG_CODE=""
    
    # Pattern 1: 2-letter language code
    if echo "$URL" | grep -qE '\.(com|net|org)/[a-z]{2}(/|$|\?)'; then
        IS_LOCALIZED=true
        LANG_CODE=$(echo "$URL" | grep -oE '\.(com|net|org)/[a-z]{2}(/|$|\?)' | grep -oE '[a-z]{2}' | head -1)
    fi
    
    # Pattern 2: 3-letter language code
    if [ "$IS_LOCALIZED" = false ] && echo "$URL" | grep -qE '\.(com|net|org)/[a-z]{3}(/|$|\?)'; then
        IS_LOCALIZED=true
        LANG_CODE=$(echo "$URL" | grep -oE '\.(com|net|org)/[a-z]{3}(/|$|\?)' | grep -oE '[a-z]{3}' | head -1)
    fi
    
    # Pattern 3: Query parameters
    if [ "$IS_LOCALIZED" = false ] && echo "$URL" | grep -qE '[?&](lang|locale)=[a-z]{2}'; then
        IS_LOCALIZED=true
        LANG_CODE=$(echo "$URL" | grep -oE '[?&](lang|locale)=[a-z]{2}' | sed 's|.*=||')
    fi
    
    # Rule 2 & 5: Decision matrix (HTTP code + Localization + Email Language)
    
    # Rule 2: Rate limiting
    if [ "$HTTP_CODE" = "429" ]; then
        echo "   ‚ö†Ô∏è HTTP 429 (rate limited) - marking as OK (assumed temporary)"
        write_result "$URL" "RATE_LIMITED" "429" "N/A" false \
            "HTTP 429 (Too Many Requests) - rate limiting detected, assumed temporary (not browser tested)"
        continue
    fi
    
    # Rule 3: 403 handling with whitelist pattern matching
    if [ "$HTTP_CODE" = "403" ]; then
        IS_WHITELISTED=false
        MATCHED_PATTERN=""
        
        # Rule 3.1: Localized patterns - LANGUAGE MUST MATCH EMAIL
        if [ "$IS_LOCALIZED" = true ] && [ "$LANG_CODE" = "$EMAIL_LANG" ]; then
            # Language code matches email language ‚Üí Check patterns
            
            # Pattern 1: Language homepages (/br, /jp, /de, etc.)
            if echo "$URL" | grep -qE '^https?://www\.autodesk\.com/[a-z]{2,3}/?(\?.*)?$'; then
                IS_WHITELISTED=true
                MATCHED_PATTERN="Language homepage (/$LANG_CODE/) matching email language ($EMAIL_LANG)"
            fi
            
            # Pattern 2: Language support pages
            if echo "$URL" | grep -qE '^https?://www\.autodesk\.com/[a-z]{2,3}/support'; then
                IS_WHITELISTED=true
                MATCHED_PATTERN="Language support page (/$LANG_CODE/support) matching email language ($EMAIL_LANG)"
            fi
            
            # Pattern 3: Language products pages
            if echo "$URL" | grep -qE '^https?://www\.autodesk\.com/[a-z]{2,3}/products'; then
                IS_WHITELISTED=true
                MATCHED_PATTERN="Language products page (/$LANG_CODE/products) matching email language ($EMAIL_LANG)"
            fi
            
            # Pattern 4: Language collections pages
            if echo "$URL" | grep -qE '^https?://www\.autodesk\.com/[a-z]{2,3}/collections'; then
                IS_WHITELISTED=true
                MATCHED_PATTERN="Language collections page (/$LANG_CODE/collections) matching email language ($EMAIL_LANG)"
            fi
            
            # Pattern 5: Language buying pages
            if echo "$URL" | grep -qE '^https?://www\.autodesk\.com/[a-z]{2,3}/buying'; then
                IS_WHITELISTED=true
                MATCHED_PATTERN="Language buying page (/$LANG_CODE/buying) matching email language ($EMAIL_LANG)"
            fi
        fi
        
        # Handle mismatched language codes
        if [ "$IS_LOCALIZED" = true ] && [ "$LANG_CODE" != "$EMAIL_LANG" ]; then
            echo "   ‚ö†Ô∏è HTTP 403 - URL language ($LANG_CODE) doesn't match email language ($EMAIL_LANG)"
            write_result "$URL" "BOT_BLOCKED" "403" "WRONG_LANGUAGE_${LANG_CODE}" true \
                "URL is localized for '$LANG_CODE' but email is in '$EMAIL_LANG' - browser test will check if /$EMAIL_LANG/ variant exists"
            continue
        fi
        
        # Rule 3.2: English-only patterns (only if email language = English)
        if [ "$IS_LOCALIZED" = false ] && [ "$EMAIL_LANG" = "en" ]; then
            # Pattern 6: English homepage
            if echo "$URL" | grep -qE '^https?://www\.autodesk\.com/?(\?.*)?$'; then
                IS_WHITELISTED=true
                MATCHED_PATTERN="English homepage (email is English)"
            fi
            
            # Pattern 7: English support page
            if echo "$URL" | grep -qE '^https?://www\.autodesk\.com/support/?(\?.*)?$'; then
                IS_WHITELISTED=true
                MATCHED_PATTERN="English support page (email is English)"
            fi
            
            # Pattern 8: English buying pages
            if echo "$URL" | grep -qE '^https?://www\.autodesk\.com/buying/'; then
                IS_WHITELISTED=true
                MATCHED_PATTERN="English buying page (email is English)"
            fi
            
            # Pattern 9: English unsubscribe
            if echo "$URL" | grep -qE '^https?://www\.autodesk\.com/mkto-unsubscribe'; then
                IS_WHITELISTED=true
                MATCHED_PATTERN="English unsubscribe page (email is English)"
            fi
        fi
        
        # Rule 3.3: Domain patterns (always whitelisted)
        # Pattern 10: Knowledge base
        if echo "$URL" | grep -qE '^https?://knowledge\.autodesk\.com/'; then
            IS_WHITELISTED=true
            MATCHED_PATTERN="Knowledge base (knowledge.autodesk.com)"
        fi
        
        # Pattern 11: Forums
        if echo "$URL" | grep -qE '^https?://forums\.autodesk\.com/'; then
            IS_WHITELISTED=true
            MATCHED_PATTERN="Community forums (forums.autodesk.com)"
        fi
        
        # Make decision based on whitelist result
        if [ "$IS_WHITELISTED" = true ]; then
            if [ "$IS_LOCALIZED" = true ]; then
                LOC_STATUS="LOCALIZED_$LANG_CODE"
            else
                LOC_STATUS="N/A"
            fi
            
            echo "   ‚úÖ HTTP 403 (whitelisted: $MATCHED_PATTERN)"
            write_result "$URL" "OK" "403" "$LOC_STATUS" false \
                "HTTP 403 from whitelisted URL pattern ($MATCHED_PATTERN) - known bot detection, verified working in browsers"
            continue
        else
            # Determine localization status for non-whitelisted 403s
            if [ "$IS_LOCALIZED" = true ]; then
                LOC_STATUS="LOCALIZED_$LANG_CODE"
            elif [ "$EMAIL_LANG" != "en" ]; then
                LOC_STATUS="NOT_LOCALIZED"
            else
                LOC_STATUS="N/A"
            fi
            
            echo "   ‚ö†Ô∏è HTTP 403 (not whitelisted) - needs browser verification"
            write_result "$URL" "BOT_BLOCKED" "403" "$LOC_STATUS" true \
                "HTTP 403 from non-whitelisted URL - browser test required to verify (localization status: $LOC_STATUS)"
            continue
        fi
    fi
    
    # HANDLE 503: Service Unavailable (ambiguous)
    if [ "$HTTP_CODE" = "503" ] && [ -n "$CONTENT_SIZE" ] && [ "$CONTENT_SIZE" -lt 5000 ]; then
        echo "   ‚ö†Ô∏è HTTP 503 (small content: ${CONTENT_SIZE} bytes) - possible bot block"
        write_result "$URL" "SUSPICIOUS" "503" "N/A" true \
            "HTTP 503 with small content (${CONTENT_SIZE} bytes) - likely bot protection, needs browser test"
        continue
    fi
    
    # Large 503 is truly broken
    if [ "$HTTP_CODE" = "503" ]; then
        echo "   ‚ùå BROKEN: HTTP 503"
        write_result "$URL" "BROKEN" "503" "N/A" false \
            "HTTP 503 Service Unavailable"
        continue
    fi
    
    # HANDLE 200: OK (with soft 404 detection and localization check)
    if [ "$HTTP_CODE" = "200" ]; then
        echo "   ‚úÖ HTTP 200"
        
        # Soft 404 detection: Small content (<1KB) = possible soft 404
        if [ -n "$CONTENT_SIZE" ] && [ "$CONTENT_SIZE" -lt 1000 ]; then
            echo "   ‚ö†Ô∏è Suspicious ($CONTENT_SIZE bytes) - will verify with browser"
            write_result "$URL" "SUSPICIOUS" "200" "N/A" true \
                "HTTP 200 but small content ($CONTENT_SIZE bytes) - possible soft 404"
            continue
        fi
        
        # Normal content size (>=1KB) - apply localization logic with language matching
        if [ "$IS_LOCALIZED" = true ]; then
            # Check if language matches email
            if [ "$LANG_CODE" = "$EMAIL_LANG" ]; then
                # Correct language! ‚úÖ
                echo "   ‚úÖ Localized: $LANG_CODE (matches email language)"
                write_result "$URL" "OK" "200" "LOCALIZED_$LANG_CODE" false \
                    "URL is localized with language code /$LANG_CODE/ matching email language"
                continue
            else
                # Wrong language! ‚ùå
                echo "   ‚ö†Ô∏è Localized as /$LANG_CODE/ but email is $EMAIL_LANG"
                write_result "$URL" "WRONG_LANGUAGE" "200" "WRONG_LANGUAGE_${LANG_CODE}" true \
                    "URL is localized for '$LANG_CODE' but email is in '$EMAIL_LANG' - browser test will check if /$EMAIL_LANG/ variant exists"
                continue
            fi
        fi
        
        # Not localized - check email language
        if [ "$EMAIL_LANG" = "en" ]; then
            echo "   ‚úÖ Not localized (OK - email is English)"
            write_result "$URL" "OK" "200" "N/A" false \
                "URL is not localized but email is in English - no localization needed"
            continue
        else
            echo "   ‚ö†Ô∏è Not localized (email is $EMAIL_LANG) - will check for /$EMAIL_LANG/ variant"
            write_result "$URL" "NOT_LOCALIZED" "200" "NOT_LOCALIZED" true \
                "URL is not localized but email is in $EMAIL_LANG - browser will check if /$EMAIL_LANG/ variant exists"
            continue
        fi
    fi
    
    # Catch-all for other HTTP codes
    echo "   ‚ö†Ô∏è HTTP $HTTP_CODE (unusual code)"
    write_result "$URL" "UNUSUAL" "$HTTP_CODE" "N/A" true \
        "Unusual HTTP code $HTTP_CODE - needs browser verification"
    
done

echo ""
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
echo "üìä PHASE 2 COMPLETE"
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
echo ""
echo "HTTP Status:"
jq -r '[.results[] | .status] | group_by(.) | .[] | "   \(.[0]): \(length) URLs"' "$RESULTS_FILE"
echo ""
echo "Localization Status:"
jq -r '[.results[] | .localizationStatus] | group_by(.) | .[] | "   \(.[0]): \(length) URLs"' "$RESULTS_FILE"
echo ""
BROWSER_COUNT=$(jq '[.results[] | select(.needsBrowserTest == true)] | length' "$RESULTS_FILE")
echo "üîç URLs requiring browser testing: $BROWSER_COUNT"
echo ""
echo "Results saved to: $RESULTS_FILE"
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
SCRIPTEOF

# Make script executable and run it
chmod +x "$VALIDATION_SCRIPT"
"$VALIDATION_SCRIPT" "$TEMP_FILE" "$RESULTS_FILE" "$DETECTED_LANGUAGE"

# Clean up script file
rm -f "$VALIDATION_SCRIPT"
```

**Step 2.1: Mark TODO #3 Complete**

---

## PHASE 2.5: MANDATORY VERIFICATION CHECKPOINT

**‚ö†Ô∏è STOP AND VERIFY BEFORE PROCEEDING TO PHASE 3**

This checkpoint ensures Phase 2 was executed correctly. **DO NOT SKIP.**

```bash
# Count links flagged for browser testing
BROWSER_TEST_COUNT=$(grep -c '"needsBrowserTest": true' "$RESULTS_FILE" 2>/dev/null || echo "0")
TOTAL_403_COUNT=$(grep -c '"httpCode": "403"' "$RESULTS_FILE" 2>/dev/null || echo "0")

echo "============================================"
echo "   PHASE 2 VERIFICATION CHECKPOINT"
echo "============================================"
echo "Total 403 responses: $TOTAL_403_COUNT"
echo "Links flagged for browser testing: $BROWSER_TEST_COUNT"
echo ""

# Validation logic
if [ "$TOTAL_403_COUNT" -gt 0 ] && [ "$BROWSER_TEST_COUNT" -eq 0 ]; then
    echo "‚ùå ERROR: Found $TOTAL_403_COUNT links with 403 status, but 0 flagged for browser testing"
    echo ""
    echo "This indicates Phase 2 403 pattern whitelist was NOT implemented correctly."
    echo ""
    echo "REQUIRED FIX:"
    echo "  1. Review lines 682-790 of this MDC file"
    echo "  2. Ensure 403s are checked against pattern whitelist"
    echo "  3. Non-whitelisted 403s MUST be flagged with needsBrowserTest: true"
    echo ""
    echo "STOPPING VALIDATION - Phase 2 must be corrected before proceeding."
    exit 1
elif [ "$BROWSER_TEST_COUNT" -gt 0 ]; then
    echo "‚úÖ VALIDATION PASSED"
    echo "   $BROWSER_TEST_COUNT links correctly flagged for Phase 3 browser testing"
    echo ""
    echo "Proceeding to Phase 3..."
else
    echo "‚úÖ VALIDATION PASSED"
    echo "   No browser testing required (all links validated via curl)"
    echo ""
    echo "Skipping Phase 3, proceeding to Phase 4..."
fi
echo "============================================"
echo ""
```

**If validation FAILS (exit 1):**
- DO NOT proceed to Phase 3
- Re-implement Phase 2 following the 403 whitelist logic (lines 682-790)
- Run this checkpoint again

**If validation PASSES:**
- Proceed to Phase 3 if `BROWSER_TEST_COUNT > 0`
- Skip to Phase 4 if `BROWSER_TEST_COUNT = 0`

---

## PHASE 3: Selective Browser Testing

‚ö†Ô∏è **CRITICAL WARNINGS - READ BEFORE EXECUTING:**
1. **DO NOT SKIP THIS PHASE** if `BROWSER_COUNT > 0`
2. **DO NOT make assumptions** about which URLs need testing
3. **DO NOT add logic** like "this type of URL doesn't need testing"
4. **TEST ALL URLs** where `needsBrowserTest == true` (NO EXCEPTIONS)
5. **Social media links are ALREADY excluded** in Phase 2 (facebook, twitter, linkedin, instagram, youtube)
6. **If this phase is skipped**, verification in Step 3.5 will FAIL

**IF there are URLs requiring browser testing, execute this phase:**

**Step 3.1: Check if browser testing is needed**

**Tool:** `run_terminal_cmd`

```bash
# Get count of URLs needing browser verification
RESULTS_FILE="<path_from_phase_2>"
BROWSER_COUNT=$(jq '[.results[] | select(.needsBrowserTest == true)] | length' "$RESULTS_FILE")

if [ "$BROWSER_COUNT" -gt 0 ]; then
    echo ""
    echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
    echo "üåê PHASE 3: BROWSER VERIFICATION"
    echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
    echo ""
    echo "Testing $BROWSER_COUNT URLs with Playwright..."
    echo ""
    
    # Save URLs to temp file for iteration
    BROWSER_URLS_FILE="/tmp/browser_urls_${EMAIL_ID}_${TIMESTAMP}.txt"
    jq -r '.results[] | select(.needsBrowserTest == true) | .originalUrl' "$RESULTS_FILE" > "$BROWSER_URLS_FILE"
    
    echo "URLs to test:"
    cat "$BROWSER_URLS_FILE"
    echo ""
else
    echo ""
    echo "‚úÖ No URLs require browser verification - skipping Phase 3"
    echo ""
fi
```

**Step 3.2: For EACH URL needing browser testing**

**IF `BROWSER_COUNT > 0`, loop through each URL:**

**For Soft 404 Detection (status = "‚ö†Ô∏è SUSPICIOUS"):**

**Tool:** `browser_navigate(URL)`

```
Navigate to the suspicious URL
```

**Tool:** `browser_wait_for({ time: 2 })`

```
Wait for page to load
```

**Tool:** `browser_evaluate(detectSoft404Function)`

```javascript
() => {
    const title = document.title.toLowerCase();
    const bodyText = document.body.textContent.toLowerCase();
    const contentLength = document.body.innerHTML.length;
    
    const titleHas404 = title.includes('404') || title.includes('not found');
    const bodyHas404 = bodyText.includes('404 not found') || 
                       bodyText.includes('page not found') ||
                       bodyText.includes('page does not exist');
    const hasMinimalContent = contentLength < 1000;
    
    const isSoft404 = (titleHas404 || bodyHas404) && hasMinimalContent;
    
    return {
        isSoft404: isSoft404,
        pageTitle: document.title,
        contentLength: contentLength,
        finalUrl: window.location.href
    };
}
```

**Then update results with terminal:**

**Tool:** `run_terminal_cmd`

```bash
# Update result based on soft 404 detection
# Use the returned values from browser_evaluate to update the status
jq '(.results[] | select(.originalUrl == "<URL>")) |= {
    originalUrl: .originalUrl,
    status: (if <isSoft404> then "‚ùå BROKEN (Soft 404)" else "‚úÖ WORKING" end),
    httpCode: .httpCode,
    localizationStatus: (if <isSoft404> then "N/A" else .localizationStatus end),
    needsBrowserTest: false,
    reason: (if <isSoft404> then "Soft 404 detected - page returns 200 but shows 404 content" else "Browser verified - real page" end),
    browserVerified: true
}' "$RESULTS_FILE" > "${RESULTS_FILE}.tmp" && mv "${RESULTS_FILE}.tmp" "$RESULTS_FILE"
```

**For Localization Testing (localizationStatus = "‚ö†Ô∏è Not Localized"):**

**Tool:** `run_terminal_cmd` (construct local URL)

```bash
# Construct suggested local URL by inserting /<DETECTED_LANG>/ after domain
ORIGINAL_URL="<url_from_results>"
SUGGESTED_LOCAL_URL=$(echo "$ORIGINAL_URL" | sed -E "s|(https?://[^/]+)(/.*)|\\1/$DETECTED_LANGUAGE\\2|")
echo "Testing local version: $SUGGESTED_LOCAL_URL"
```

**Tool:** `browser_navigate(SUGGESTED_LOCAL_URL)`

```
Navigate to suggested localized URL
```

**Tool:** `browser_wait_for({ time: 2 })`

**Tool:** `browser_evaluate(checkLocalVersionFunction)`

```javascript
() => {
    const is404 = document.title.toLowerCase().includes('404') || 
                  document.body.textContent.toLowerCase().includes('404');
    const isEmpty = document.body.innerHTML.length < 100;
    const isBroken = is404 || isEmpty;
    
    return {
        localVersionExists: !isBroken,
        pageTitle: document.title,
        finalUrl: window.location.href
    };
}
```

**Then update results:**

**Tool:** `run_terminal_cmd`

```bash
# Update result based on local version test
jq '(.results[] | select(.originalUrl == "<ORIGINAL_URL>")) |= {
    originalUrl: .originalUrl,
    status: .status,
    httpCode: .httpCode,
    localizationStatus: (if <localVersionExists> then "‚ö†Ô∏è Local version exists: <SUGGESTED_LOCAL_URL>" else "‚úÖ No local version (English OK)" end),
    needsBrowserTest: false,
    reason: (if <localVersionExists> then "Local version found but not used in email" else "No local version available - English is appropriate" end),
    browserVerified: true,
    suggestedUrl: (if <localVersionExists> then "<SUGGESTED_LOCAL_URL>" else null end)
}' "$RESULTS_FILE" > "${RESULTS_FILE}.tmp" && mv "${RESULTS_FILE}.tmp" "$RESULTS_FILE"
```

**Step 3.3: Loop back to Step 3.2 for next URL**

(Repeat Step 3.2 for each URL in the list)

---

**Step 3.4: Mark Phase 3 Complete**

**Tool:** `run_terminal_cmd`

```bash
echo ""
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
echo "‚úÖ PHASE 3 COMPLETE"
echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
echo ""
echo "Browser verification completed for $BROWSER_COUNT URLs"
echo ""
```

---

**Step 3.5: ‚ö†Ô∏è VERIFICATION CHECKPOINT - Ensure Phase 3 Was Not Skipped**

‚ö†Ô∏è **MANDATORY: This step MUST be executed before proceeding to Phase 4**

**Tool:** `run_terminal_cmd`

‚ö†Ô∏è **IMPORTANT:** Use temp script approach to prevent terminal buffer issues

```bash
# Create temporary verification script to avoid terminal buffer overflow
VERIFY_SCRIPT="/tmp/verify_$(date +%s).sh"
RESULTS_FILE="<path_from_phase_2>"

cat > "$VERIFY_SCRIPT" << 'VERIFY_EOF'
#!/bin/bash
RESULTS_FILE="REPLACE_WITH_ACTUAL_PATH"

echo ""
echo "=================================================="
echo "Phase 3.5: VERIFICATION CHECKPOINT"
echo "=================================================="
echo ""

# Count URLs that NEEDED browser testing
NEEDED_COUNT=$(jq '[.results[] | select(.needsBrowserTest == true)] | length' "$RESULTS_FILE")

# Count URLs that WERE verified (status updated after browser test)
VERIFIED_COUNT=$(jq '[.results[] | select(.needsBrowserTest == true and (.status == "OK" or .status == "BROKEN" or .status == "NOT LOCALIZED"))] | length' "$RESULTS_FILE")

echo "Browser testing summary:"
echo "  - URLs that needed browser testing: $NEEDED_COUNT"
echo "  - URLs actually verified: $VERIFIED_COUNT"
echo ""

if [ "$NEEDED_COUNT" -eq 0 ]; then
    echo "No URLs required browser testing"
elif [ "$VERIFIED_COUNT" -eq "$NEEDED_COUNT" ]; then
    echo "All flagged URLs were successfully tested!"
else
    echo "FATAL ERROR: Phase 3 was not properly executed!"
    echo "  Expected: $NEEDED_COUNT URLs to test"
    echo "  Actual: $VERIFIED_COUNT URLs tested"
    echo ""
    echo "  This indicates Phase 3 (Selective Browser Testing) was skipped."
    exit 1
fi

echo ""
echo "=================================================="
echo "Verification Complete"
echo "=================================================="
VERIFY_EOF

# Replace placeholder with actual path
sed -i '' "s|REPLACE_WITH_ACTUAL_PATH|$RESULTS_FILE|g" "$VERIFY_SCRIPT"

# Execute the script
chmod +x "$VERIFY_SCRIPT"
"$VERIFY_SCRIPT"
```

**Expected output:**
- ‚úÖ If no URLs needed testing: "No URLs required browser testing - Phase 3 skip was valid"
- ‚úÖ If all URLs were tested: "VERIFICATION PASSED: All URLs were properly tested"
- ‚ùå If Phase 3 was skipped: "FATAL ERROR: Phase 3 was SKIPPED!" ‚Üí **STOP and re-run Phase 3**
- ‚ö†Ô∏è If partially done: "WARNING: Phase 3 was partially executed" ‚Üí **Review and complete**

---

## PHASE 3 (Original Documentation for Reference)

**Only execute this phase for URLs where `needsBrowserTest == true`**

**Step 3.1: Get List of URLs to Test**

**Tool:** `run_terminal_cmd`

```bash
# Extract URLs that need browser testing
jq -r '.results[] | select(.needsBrowserTest == true) | .originalUrl' "$RESULTS_FILE"
```

**Step 3.2: For EACH Flagged URL**

**Determine Test Type:**
- If status = "‚ö†Ô∏è SUSPICIOUS" ‚Üí Test for soft 404
- If localization = "‚ö†Ô∏è Not Localized" ‚Üí Test suggested local version

**For Soft 404 Verification:**

**Tools:** `browser_navigate(URL)` ‚Üí `browser_wait_for({ time: 2 })` ‚Üí `browser_evaluate(detectSoft404)`

```javascript
function detectSoft404() {
    const title = document.title.toLowerCase();
    const bodyText = document.body.textContent.toLowerCase();
    const contentLength = document.body.innerHTML.length;
    
    const titleHas404 = title.includes('404') || title.includes('not found');
    const bodyHas404 = bodyText.includes('404 not found') || 
                       bodyText.includes('page not found') ||
                       bodyText.includes('page does not exist');
    const hasMinimalContent = contentLength < 1000;
    
    const isSoft404 = (titleHas404 || bodyHas404) && hasMinimalContent;
    
    return {
        isSoft404: isSoft404,
        pageTitle: document.title,
        contentLength: contentLength,
        finalUrl: window.location.href
    };
}
```

**For Local Version Testing:**

**Tools:** `browser_navigate(suggestedLocalUrl)` ‚Üí `browser_wait_for({ time: 2 })` ‚Üí `browser_evaluate(checkLocalVersion)`

```javascript
function checkLocalVersion() {
    const is404 = document.title.toLowerCase().includes('404') || 
                  document.body.textContent.toLowerCase().includes('404');
    const isEmpty = document.body.innerHTML.length < 100;
    const isBroken = is404 || isEmpty;
    
    return {
        exists: !isBroken,
        pageLanguage: document.documentElement.lang || 'en',
        pageTitle: document.title,
        finalUrl: window.location.href
    };
}
```

**Step 3.3: Update Results File**

**Tool:** `run_terminal_cmd`

```bash
# Update results with browser findings
jq --arg url "$TESTED_URL" \
   --arg browserResult "$BROWSER_RESULT" \
   '(.results[] | select(.originalUrl == $url)) |= . + {"browserResult": $browserResult}' \
   "$RESULTS_FILE" > "${RESULTS_FILE}.tmp" && mv "${RESULTS_FILE}.tmp" "$RESULTS_FILE"
```

**Step 3.4: Mark TODO #4 Complete**

---

## PHASE 4: Generate CSV Report

**Tool:** `run_terminal_cmd`

‚ö†Ô∏è **REQUIRED CSV FORMAT (DO NOT CHANGE):**
```
CTA #,Anchor Text,Link URL,HTTP Status,Localization Status,Browser Verification,Recommendation
```

**Column Descriptions:**
1. **CTA #** - Row number (1, 2, 3...)
2. **Anchor Text** - Visible link text (e.g., "Learn More", "Get Started", "View in browser")
3. **Link URL** - Full URL (e.g., `https://www.autodesk.com/products`)
4. **HTTP Status** - Combined status + HTTP code (e.g., "‚úÖ OK (200)", "‚ùå BROKEN (404)")
5. **Localization Status** - Whether link is localized (e.g., "‚úÖ LOCALIZED (/cz)", "‚ùå NOT LOCALIZED")
6. **Browser Verification** - Result from Phase 3 browser test (e.g., "‚úÖ Verified working", "N/A")
7. **Recommendation** - Actionable advice (e.g., "No action needed", "Fix: Use /cz/support instead")

```bash
#!/bin/bash
TEMP_FILE="<path_from_phase_1>"
RESULTS_FILE="<path_from_phase_2>"
DETECTED_LANGUAGE="<from_phase_1>"
PREVIEW_ID="<from_url>"
TIMESTAMP=$(date +"%Y-%m-%dT%H-%M-%S")

OUTPUT_CSV="$HOME/Downloads/${DETECTED_LANGUAGE}-LinkValidation-${PREVIEW_ID}-${TIMESTAMP}.csv"

# Write CSV Header (EXACT FORMAT - DO NOT MODIFY)
echo "CTA #,Anchor Text,Link URL,HTTP Status,Localization Status,Browser Verification,Recommendation" > "$OUTPUT_CSV"

# Process each link from allLinks
jq -c '.allLinks[]' "$TEMP_FILE" | nl -w1 -s'|' | while IFS='|' read -r INDEX CTA; do
    URL=$(echo "$CTA" | jq -r '.href')
    ANCHOR=$(echo "$CTA" | jq -r '.text' | sed 's/"/""/g')  # Escape quotes for CSV
    
    # Look up validation result from Phase 2/3
    RESULT=$(jq --arg url "$URL" '.results[] | select(.originalUrl == $url)' "$RESULTS_FILE")
    
    if [ -z "$RESULT" ]; then
        # URL not in results (shouldn't happen)
        STATUS="‚ö†Ô∏è NOT TESTED"
        LOCALIZATION="N/A"
        BROWSER_VERIFY="N/A"
        RECOMMENDATION="Error: URL not found in validation results"
    else
        STATUS_EMOJI=$(echo "$RESULT" | jq -r '.status')
        HTTP_CODE=$(echo "$RESULT" | jq -r '.httpCode // "N/A"')
        LOCALIZATION=$(echo "$RESULT" | jq -r '.localizationStatus')
        BROWSER_RESULT=$(echo "$RESULT" | jq -r '.browserResult // "Not tested"')
        
        # Combine status with HTTP code for "HTTP Status" column
        if [ "$HTTP_CODE" = "N/A" ]; then
            STATUS="$STATUS_EMOJI"
        else
            STATUS="$STATUS_EMOJI ($HTTP_CODE)"
        fi
        
        # Add emojis to status for CSV display
        case "$STATUS_EMOJI" in
            "OK") STATUS="‚úÖ OK ($HTTP_CODE)" ;;
            "BROKEN") STATUS="‚ùå BROKEN ($HTTP_CODE)" ;;
            "SUSPICIOUS") STATUS="‚ö†Ô∏è SUSPICIOUS ($HTTP_CODE)" ;;
            "NOT_LOCALIZED") STATUS="‚ö†Ô∏è NOT LOCALIZED ($HTTP_CODE)" ;;
            "BOT_BLOCKED") STATUS="‚ö†Ô∏è BOT-BLOCKED ($HTTP_CODE)" ;;
            "RATE_LIMITED") STATUS="‚ö†Ô∏è RATE-LIMITED ($HTTP_CODE)" ;;
            "MISSING_LINK") STATUS="‚ö†Ô∏è MISSING LINK ($HTTP_CODE)" ;;
            "UNUSUAL") STATUS="‚ö†Ô∏è UNUSUAL ($HTTP_CODE)" ;;
            *) STATUS="$STATUS_EMOJI ($HTTP_CODE)" ;;
        esac
        
        # Add emojis to localization status for CSV display
        case "$LOCALIZATION" in
            LOCALIZED_*) 
                LANG=$(echo "$LOCALIZATION" | sed 's/LOCALIZED_//')
                LOCALIZATION="‚úÖ LOCALIZED (/$LANG/)"
                ;;
            "SOCIAL_MEDIA") LOCALIZATION="‚úÖ SOCIAL MEDIA (No local version)" ;;
            "GLOBAL_SERVICE") LOCALIZATION="‚úÖ GLOBAL SERVICE (No local version)" ;;
            "PRELOADED") LOCALIZATION="‚úÖ PRELOADED" ;;
            "NOT_LOCALIZED") LOCALIZATION="‚ö†Ô∏è NOT LOCALIZED" ;;
        esac
        
        # Generate recommendation based on status
        if [[ "$STATUS_EMOJI" == "BROKEN" ]]; then
            RECOMMENDATION="Fix: Link returns HTTP error"
            BROWSER_VERIFY="N/A"
        elif [[ "$STATUS_EMOJI" == "RATE_LIMITED" ]]; then
            RECOMMENDATION="Consider reviewing - rate limit detected but not verified"
            BROWSER_VERIFY="N/A (skipped)"
        elif [[ "$STATUS_EMOJI" == "MISSING_LINK" ]]; then
            RECOMMENDATION="Fix: Anchor placeholder detected - add actual link target"
            BROWSER_VERIFY="N/A"
        elif [[ "$STATUS_EMOJI" == "NOT_LOCALIZED" ]]; then
            # Extract suggested URL from reason if available
            REASON=$(echo "$RESULT" | jq -r '.reason // ""')
            if [[ "$REASON" =~ "available at" ]]; then
                SUGGESTED_URL=$(echo "$REASON" | grep -oP 'https://[^\s]+' | head -1)
                RECOMMENDATION="Fix: Use localized version: $SUGGESTED_URL"
            else
                RECOMMENDATION="Consider localizing this link"
            fi
            BROWSER_VERIFY="Local version exists"
        elif [[ "$STATUS_EMOJI" == "SUSPICIOUS" ]]; then
            if [[ "$BROWSER_RESULT" == *"isSoft404\":true"* ]]; then
                RECOMMENDATION="Fix: Soft 404 detected"
                BROWSER_VERIFY="‚ùå Broken (Soft 404)"
            else
                RECOMMENDATION="No action needed"
                BROWSER_VERIFY="‚úÖ Verified working"
            fi
        elif [[ "$LOCALIZATION" == *"GLOBAL SERVICE"* ]] || [[ "$LOCALIZATION" == *"SOCIAL MEDIA"* ]]; then
            RECOMMENDATION="No action needed (no localized versions exist)"
            BROWSER_VERIFY="N/A"
        elif [[ "$LOCALIZATION" == *"LOCALIZED"* ]]; then
            RECOMMENDATION="No action needed"
            BROWSER_VERIFY="N/A"
        elif [[ "$LOCALIZATION" == *"NOT LOCALIZED"* ]]; then
            if [[ "$BROWSER_RESULT" == *"exists\":true"* ]]; then
                LOCAL_URL=$(echo "$BROWSER_RESULT" | jq -r '.finalUrl')
                RECOMMENDATION="Consider using local version: $LOCAL_URL"
                BROWSER_VERIFY="‚úÖ Local version exists"
            else
                RECOMMENDATION="No local version available"
                BROWSER_VERIFY="‚ùå Local version not found"
            fi
        else
            RECOMMENDATION="Review status"
            BROWSER_VERIFY="$BROWSER_RESULT"
        fi
    fi
    
    # Write CSV row
    echo "$INDEX,\"$ANCHOR\",\"$URL\",\"$STATUS\",\"$LOCALIZATION\",\"$BROWSER_VERIFY\",\"$RECOMMENDATION\"" >> "$OUTPUT_CSV"
done

echo "‚úÖ CSV generated: $OUTPUT_CSV"
cat "$OUTPUT_CSV"
```

**Step 4.1: Mark TODO #5 Complete**

---

## PHASE 5: Verification + Cleanup

**Step 5.1: Preview CSV, Generate Summary, Copy to Downloads, and Cleanup**

**Tool:** `run_terminal_cmd`

‚ö†Ô∏è **IMPORTANT:** Use temp script approach to prevent terminal buffer issues

```bash
# Create temporary Phase 5 script to avoid terminal buffer overflow
PHASE5_SCRIPT="/tmp/phase5_$(date +%s).sh"
CSV_FILE="<actual_csv_filename>"
TEMP_FILE="<path_from_phase_1>"
RESULTS_FILE="<path_from_phase_2>"

cat > "$PHASE5_SCRIPT" << 'PHASE5_EOF'
#!/bin/bash
CSV_FILE="REPLACE_CSV"
TEMP_FILE="REPLACE_TEMP"
RESULTS_FILE="REPLACE_RESULTS"

echo ""
echo "CSV Preview (first 5 rows):"
head -5 "$CSV_FILE"
echo ""

echo "Validation Summary:"
TOTAL=$(tail -n +2 "$CSV_FILE" | wc -l | tr -d ' ')
OK_COUNT=$(grep -c 'OK' "$CSV_FILE" || echo "0")
BROKEN_COUNT=$(grep -c 'BROKEN' "$CSV_FILE" || echo "0")
ISSUES_COUNT=$(grep -c 'MISSING LINK\|NOT LOCALIZED' "$CSV_FILE" || echo "0")

echo "   Total links: $TOTAL"
echo "   OK: $OK_COUNT"
echo "   BROKEN: $BROKEN_COUNT"
echo "   ISSUES: $ISSUES_COUNT"
echo ""

# Copy to Downloads
cp "$CSV_FILE" ~/Downloads/
echo "CSV copied to ~/Downloads/$CSV_FILE"
echo ""

# Cleanup temp files
echo "Cleaning up temporary files..."
rm -f "$TEMP_FILE" "$RESULTS_FILE" /tmp/validate_*.sh /tmp/verify_*.sh /tmp/phase5_*.sh /tmp/curl_body_*.html 2>/dev/null
echo "Cleanup complete"
echo ""

echo "=================================================="
echo "VALIDATION COMPLETE!"
echo "=================================================="
echo ""
echo "Report: ~/Downloads/$CSV_FILE"
PHASE5_EOF

# Replace placeholders with actual values
sed -i '' "s|REPLACE_CSV|$CSV_FILE|g" "$PHASE5_SCRIPT"
sed -i '' "s|REPLACE_TEMP|$TEMP_FILE|g" "$PHASE5_SCRIPT"
sed -i '' "s|REPLACE_RESULTS|$RESULTS_FILE|g" "$PHASE5_SCRIPT"

# Execute the script
chmod +x "$PHASE5_SCRIPT"
"$PHASE5_SCRIPT"
```

**Step 5.2: Mark TODO #7 Complete**

---

## üìä Final Output

**Deliver to User:**
1. CSV file location: `~/Downloads/${LANG}-LinkValidation-${ID}-${TIMESTAMP}.csv`
2. Summary statistics (broken, localized, tested, etc.)
3. Token usage estimate
4. Validation complete message

---

## üìù AI Assistant Execution Notes

### Critical Rules:
1. ‚úÖ **Create TODO list first** (mandatory)
2. ‚úÖ **Update TODO after each phase** (show progress)
3. ‚úÖ **Use actual values** (no placeholders like `<EMAIL_URL>`)
4. ‚úÖ **Save temp files with actual IDs** (extract from URL)
5. ‚úÖ **Test ALL flagged URLs** (no skipping)
6. ‚úÖ **Read from temp files** (not memory) for CSV generation
7. ‚úÖ **Verify CSV** before delivering
8. ‚úÖ **Clean up** temp files after verification

### Execution Flow:
```
User provides: https://webpub.autodesk.com/draftr/preview/XXXXXX

AI executes:
‚îú‚îÄ TODO_WRITE (create checklist)
‚îú‚îÄ BROWSER_NAVIGATE (extract links)
‚îú‚îÄ RUN_TERMINAL_CMD (save to /tmp/email_extraction_XXXXXX_*.json)
‚îú‚îÄ RUN_TERMINAL_CMD (curl validation ‚Üí /tmp/smart_validation_XXXXXX_*.json)
‚îú‚îÄ BROWSER_NAVIGATE √ó N (test flagged URLs only)
‚îú‚îÄ RUN_TERMINAL_CMD (generate CSV ‚Üí ~/Downloads/*.csv)
‚îú‚îÄ BROWSER_NAVIGATE (verify CSV)
‚îú‚îÄ RUN_TERMINAL_CMD (cleanup temp files)
‚îî‚îÄ TODO_WRITE (mark all complete)
```

### Token Estimate:
- Phase 1: ~40k tokens
- Phase 2: 0 tokens (pure curl)
- Phase 3: ~40k √ó N flagged URLs (typically 2-5)
- Phase 4-5: ~10k tokens
- **Total: ~150k-250k tokens** (vs 840k+ old approach)

---

## üéØ User Experience

**User types:**
> "Validate this email: https://webpub.autodesk.com/draftr/preview/XXXXXX"

**AI responds:**
> "I'll validate all links in that email. This will take about 30-60 seconds.
> 
> [Creates TODO list]
> [Executes all phases automatically]
> [Generates CSV]
> 
> ‚úÖ Validation complete!
> 
> **Summary:**
> - Total CTAs: [X]
> - Unique URLs: [Y]
> - ‚ùå Broken: [n]
> - ‚úÖ Working & Localized: [n]
> - ‚ö†Ô∏è Not Localized: [n] (local versions found)
> 
> **CSV Report:** ~/Downloads/[lang]-LinkValidation-XXXXXX-YYYY-MM-DDTHH-MM-SS.csv
> 
> **Token Usage:** ~180k tokens (85% savings vs old approach)"

**User does nothing else** - CSV is ready to use!

---

**END OF MDC**
